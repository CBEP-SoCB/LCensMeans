---
title: "Testing"
output: html_notebook
---

```{r}
library(dplyr)
```



```{r}
test<- function(lmu, lsigma, cutoff,  sz = 1000) {
  # I'm a little unsure when to throw an error and when to return NA, as
  # this is an internal utility function.  The function will often be
  # called for each value in a vector, so in general we don't
  # want it to fail catastrophically, but would rather it return NA,
  # perhaps with a warning.
  
  stopifnot(cutoff > 0)
  plower <- stats::plnorm(cutoff, lmu, lsigma)
  
  if (plower == 0)
    stop('Probability density below the cutoff (= ', cutoff, ') is zero.')
  
  estsamplesz <- sz + as.integer(sz / plower)  # Guess how many (usually guess high).
  
  if (estsamplesz > 10^6) {
    warning("Estimated sample size required > 1 million. Returning NA.\n")
    return(NA_real_)
  }
  else
    message('Starting number of samples = ', estsamplesz, '.\n')
  
  rawsample <- stats::rlnorm(estsamplesz, lmu, lsigma) # efficiently calculate guess
  while(sum(rawsample<=cutoff) < sz) {
    cat('.')
    rawsample <- append(rawsample, stats::rlnorm(100, lmu, lsigma))
  }
  cat('\n')
  message('Any dots represent 100 additional samples each.\n')
  
  smple <- rawsample[rawsample <= cutoff]             # Throw out if too large
  smple <- smple[1:sz]                                # Take the sample

  return(mean(smple, na.rm=TRUE))                                  # Calculate the mean
}

```



```{r}
test(0,0,0)
```

```{r}
test(0,0,1)
```

```{r}
test(0,0,1.1)
```

```{r}
test(0,1,0.1)
```
When the required sample size is exceptionally large, we return NA to avoid
bogging down calculations. Even this only works because the sample is discarded when
the function is returned (or more correctly, at the next garbage collection).
That means successive passes through the function don't just keep hogging memory.

Under these circumstances, is there a better choice that returning NA?
```{r}
test(0,1,0.05)
```
